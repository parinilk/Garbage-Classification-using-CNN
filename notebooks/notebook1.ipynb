{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing Libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting the path and the labels list for classification of targets on the basis in human understandable form\n",
    "\n",
    "train_dir = os.path.join(\"D:\\work\\Projects\\Garbage Classification using CNN\\dataset\", \"training\")\n",
    "labels = ['cardboard', 'glass', 'metal', 'paper', 'plastic', 'trash']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking the size of data available to us for training out model\n",
    "\n",
    "for label in labels:\n",
    "    directory = os.path.join(train_dir, label)\n",
    "    print(\"Images of label \\\"\" + label + \"\\\":\\t\", len(os.listdir(directory)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting images of different review for understanding the dataset\n",
    "\n",
    "plt.figure(figsize=(30,14))\n",
    "\n",
    "for i in range(6):\n",
    "    directory = os.path.join(train_dir, labels[i])\n",
    "    for j in range(10):\n",
    "        path = os.path.join(directory, os.listdir(directory)[j])\n",
    "        img = mpimg.imread(path)\n",
    "        \n",
    "        plt.subplot(6, 10, i*10 + j + 1)\n",
    "        plt.imshow(img)\n",
    "        \n",
    "        if j == 0:\n",
    "            plt.ylabel(labels[i], fontsize=20)\n",
    "        \n",
    "plt.setp(plt.gcf().get_axes(), xticks=[], yticks=[]);\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking size of individual image\n",
    "\n",
    "directory = os.path.join(train_dir, 'cardboard')\n",
    "path = os.path.join(directory, os.listdir(directory)[0])\n",
    "image = mpimg.imread(path)\n",
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the model\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "  tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(384, 512, 3)),\n",
    "  tf.keras.layers.BatchNormalization(),\n",
    "  tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),\n",
    "  tf.keras.layers.BatchNormalization(),\n",
    "  tf.keras.layers.MaxPooling2D(2, 2),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "    \n",
    "  tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "  tf.keras.layers.BatchNormalization(),\n",
    "  tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "  tf.keras.layers.BatchNormalization(),\n",
    "  tf.keras.layers.MaxPooling2D(2, 2),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "\n",
    "  tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "  tf.keras.layers.BatchNormalization(),\n",
    "  tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "  tf.keras.layers.BatchNormalization(),\n",
    "  tf.keras.layers.MaxPooling2D(2, 2),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "\n",
    "  tf.keras.layers.Conv2D(256, (3, 3), activation='relu'),\n",
    "  tf.keras.layers.BatchNormalization(),\n",
    "  tf.keras.layers.Conv2D(256, (3, 3), activation='relu'),\n",
    "  tf.keras.layers.BatchNormalization(),\n",
    "  tf.keras.layers.MaxPooling2D(2, 2),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "    \n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(512, activation='relu'),\n",
    "  tf.keras.layers.BatchNormalization(),\n",
    "  tf.keras.layers.Dropout(0.4),\n",
    "  tf.keras.layers.Dense(6, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=keras.optimizers.Adam(learning_rate = 0.0001), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating generators for combining data and increasing the gainable insights by slightly modifying the images in the dataset\n",
    "\n",
    "train_datagen = ImageDataGenerator(horizontal_flip=True,vertical_flip=True,\n",
    "                                   rotation_range=15,zoom_range=0.1,\n",
    "                                   width_shift_range=0.15,height_shift_range=0.15,\n",
    "                                   shear_range=0.1,\n",
    "                                   fill_mode=\"nearest\",\n",
    "                                   rescale=1./255., \n",
    "                                   validation_split=0.2)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(train_dir, target_size=(384, 512), batch_size=32, class_mode='binary', subset='training')\n",
    "validation_generator = train_datagen.flow_from_directory(train_dir, target_size=(384, 512), batch_size=32, class_mode='binary', subset='validation')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the callback function so that it can be used to end the training in case reached a good accuracy rate (above 90%)\n",
    "\n",
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if(logs.get('accuracy')>0.90):\n",
    "            print(\"\\nReached 90% accuracy so cancelling training!\")\n",
    "            self.model.stop_training = True\n",
    "\n",
    "callbacks = myCallback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_generator, epochs=50, verbose=1, validation_data=validation_generator, callbacks=[callbacks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(model, open('../models/cnn_model.pkl', 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
